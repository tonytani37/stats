{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "スタッツデータ作成.ipynb ",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonytani37/stats/blob/main/%E3%82%B9%E3%82%BF%E3%83%83%E3%83%84%E3%83%87%E3%83%BC%E3%82%BF%E4%BD%9C%E6%88%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U4jZqO9cwDw"
      },
      "source": [
        "# まずは前提条件\n",
        "Googleアカウントが必須です。\n",
        "\n",
        "ブラウザは最新のChromeの利用を強く推奨します。(Microsoft Edgeの最新版は大丈夫ですが、古いEdgeやIEは動かないかもしれません。FirefoxやSafariでは動くと思います）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9YB5vUGa9Hr"
      },
      "source": [
        "## 注意事項\n",
        "### 処理自体は膨大な能力を持つGoogleクラウド上で実行されるので、目の前のパソコンが多少古くてもあまり心配することはありません。\n",
        "\n",
        "１．説明を読んで、上から順番に番号順に処理をしてください。\n",
        "\n",
        "２．処理はそれぞれの機能ごとに分けてありますので、今後修正したい場合にはその部分だけ差し替えればオーケーです。\n",
        "\n",
        "３．処理によっては実行するとその下によくわからない文字がずらずらと表示されるものとされないものがあります。どのタイミングで処理が終わったかわかりづらいかもしれないので、各処理が完了すると「x おわり」と表示するようにしていますで、そこまで我慢してください。（表示されるメッセージのnは処理の番号です）\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l5AbnEBgkg3"
      },
      "source": [
        "# さあ、はじめましょう\n",
        "ここから処理が始まります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObTBQNY4PHhR"
      },
      "source": [
        "### 最初にデータ化したいPDFファイルを入手します\n",
        "1-1 は自分のPCにあるPDFファイルを変換したい場合に使います。\n",
        "\n",
        "1-2 はよくわからないけどとりあえず練習用に試してみたい人向けに、Xリーグのホームページにある2019/8/24の富士通フロンティアーズ対IBM BigBlueの対戦のものがダウンロードされます。\n",
        "\n",
        "どちらか一つ、好きな方を実行してください。（1-1の場合は、以降使われるPDFファイル名や画像データ名が以下にあるものと異なるので、適宜変更してくださいね）\n",
        "\n",
        "# 初回の実行時に「これはGoogleが提供してないけど実行する？」的なメッセージが出るかも知れませんが、気にせず実行して下さい。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVn2bJvtQNcT"
      },
      "source": [
        "その１）自分のPCにあるPDFファイルを変換したい場合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leVVAUOrc46Y"
      },
      "source": [
        "# 1-1\n",
        "#OCRであつかうPDFファイルを読み込む（変換したいPC上のファイルを指定してくだされ）\n",
        "from google.colab import files\n",
        "f = files.upload()\n",
        "#読み込んだ画像のファイル名\n",
        "filename = list(f)[0]\n",
        "\n",
        "print('1-1 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaZIBzcHQSZE"
      },
      "source": [
        "その２）とりあえず試してみたい場合　"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1pjztOfP8N9"
      },
      "source": [
        "# 1-2\n",
        "#OCRであつかうPDFファイルを読み込む（練習用に特定のPDFファイルをダウンロードしてくる）\n",
        "!rm -r /content/pdf/\n",
        "!mkdir /content/pdf/\n",
        "\n",
        "! wget -c -P '/content/pdf/' 'https://xleague.s3.ap-northeast-1.amazonaws.com/wp-content/uploads/2019/07/20190824_X1_FF_BB_921.pdf'\n",
        "# filename = \"20190824_X1_FF_BB_921.pdf\"\n",
        "\n",
        "print('1-2 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVU-xfCkNtVg"
      },
      "source": [
        "### PDFを画像へ変換します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5NhxslFWovy"
      },
      "source": [
        "# 2\n",
        "# PDFから画像へ変換するためのライブラリ、ツールを準備する\n",
        "!apt-get install poppler-utils \n",
        "!pip install pdf2image\n",
        "\n",
        "print('2 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX0BTtORaolH"
      },
      "source": [
        "# 3\n",
        "# 画像データに変換する処理\n",
        "from pathlib import Path\n",
        "from pdf2image import convert_from_path\n",
        "import glob\n",
        "\n",
        "# Google Colabのデフォルト環境内にimageというフォルダを作る\n",
        "!rm -r /content/image/\n",
        "!mkdir /content/image/\n",
        "\n",
        "def pdf2img(filename):\n",
        "    pdf_path = Path(filename)\n",
        "    #outputのファイルパス（この場合は上でつくったimageフォルダを指定）\n",
        "    img_path=Path(\"/content/image/\")\n",
        "\n",
        "    #変換されたjpegファイルがimg_pathで指定されたフォルダに保存されます\n",
        "    convert_from_path(pdf_path, output_folder=img_path,fmt='jpeg',output_file=pdf_path.stem)\n",
        "\n",
        "#フォルダにあるPDFファイルの一覧を取得する\n",
        "pdf_list = glob.glob('/content/pdf/*.pdf')\n",
        "\n",
        "for row in pdf_list:\n",
        "    pdf2img(row)\n",
        "\n",
        "print('3 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElrGaxyMN7HG"
      },
      "source": [
        "### 以上で画像変換完了。PDFに複数ページがある場合、ページごとに画像データ（ファイル名末尾が連番）が作成されるので、一つのPDFファイルから複数の画像ファイルが作成されたとしても、驚かないこと。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fXjEWqCNm-c"
      },
      "source": [
        "### ここからOCR読み込み処理です。まずは準備しましょう\n",
        "最初にOCR読み込み用のライブラリとツールをインストールします"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAGP267sZB4D"
      },
      "source": [
        "# 4\n",
        "# Tesseract OCRの関連ライブラリを準備する\n",
        "# OCR読み込みに必要なツールをインストールします\n",
        "!apt install tesseract-ocr\n",
        "!apt install libtesseract-dev\n",
        "!pip install pyocr\n",
        "\n",
        "#日本語トレーニングデータのダウンロードとして環境設定します\n",
        "!curl -L https://github.com/tesseract-ocr/tessdata/raw/master/jpn.traineddata > jpn.traineddata\n",
        "!cp jpn.traineddata /usr/share/tesseract-ocr/4.00/tessdata\n",
        "\n",
        "# PythonでOCR読み込み変換に必要なライブラリを準備します\n",
        "from PIL import Image\n",
        "import pyocr\n",
        "import pyocr.builders\n",
        "\n",
        "print('4 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHwdTN3PZLoc"
      },
      "source": [
        " # 5\n",
        " #日本語トレーニングデータのダウンロードとして環境設定します\n",
        "!curl -L https://github.com/tesseract-ocr/tessdata/raw/master/jpn.traineddata > jpn.traineddata\n",
        "!cp jpn.traineddata /usr/share/tesseract-ocr/4.00/tessdata\n",
        "print('5 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXoCx9rLZR4n"
      },
      "source": [
        "# 6\n",
        "# PythonでOCR読み込み変換に必要なライブラリを準備します\n",
        "from PIL import Image\n",
        "import pyocr\n",
        "import pyocr.builders\n",
        "\n",
        "print('6 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbZOm_6eOWLX"
      },
      "source": [
        "### OCR読み込みの前に、必要なツールがインストールされているか確認しませう。\n",
        "うまくいかない場合は環境構築が間違っているので、最初からもう一度がんばろう。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcjK7gd2XROO"
      },
      "source": [
        "OCR tool is 'Tesseract (sh)' と表示されればオーケー"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJIfOdP4ZXTV"
      },
      "source": [
        "# 7\n",
        "#OCRが使用可能かの設定状態チェックしてみる\n",
        "tools = pyocr.get_available_tools()\n",
        "if len(tools) == 0:\n",
        "    print(\"OCR tool is not found\")\n",
        "    sys.exit(1)\n",
        "\n",
        "#OCRツール名を表示\n",
        "tool = tools[0]\n",
        "print(\"OCR tool is '%s'\" % (tool.get_name()))\n",
        "\n",
        "print('7 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC_wIocpXWYn"
      },
      "source": [
        "Available languages:　の次に　jpn　が入ってればオーケー（その他 osd,engなどもあるはず。もしかするとないものもあるかもしれないけど、とりあえず jpn が入っていればオーケー）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47wmY8pRZeMV"
      },
      "source": [
        "# 8\n",
        "#OCR対応言語を表示して'jpn'が入っているか確認してみる\n",
        "langs = tool.get_available_languages()\n",
        "print(\"Available languages: %s\" % \", \".join(langs))\n",
        "lang = langs[0]\n",
        "print(\"Will use lang '%s'\" % (lang))\n",
        "\n",
        "print('8 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdYp8pLyOjmY"
      },
      "source": [
        "### ここから実際のOCR読み込み処理です。\n",
        "ここでは、fnameという変数にファイルのパスをセットしています。Google Colaboでは画面左側に作成されたファイルを扱うので、デフォルトの'/content/以降の部分に読み込みたい画像ファイル名(pathも正しく指定してね)を指定してください。ファイル名とパスの指定は、読み込みたいファイルを右クリックすると「パスをコピー」という項目があるので、そいつをクリックしてコピーし、fname = 以降に”または’のどちらかで囲って、その間にペーストすればオーケーです。\n",
        "\n",
        "(本当は特定のフィルだにある画像ファイルを一括で処理できればいいんだろうけれど、そういうやつは次に考えます）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haMQ6aWDeOxw"
      },
      "source": [
        "# 9\n",
        "#読み込んだ画像をOCRでテキスト抽出。\n",
        "\n",
        "#うまく変換できなかった文字を強制的に置き換える\n",
        "conv_text = {\"①\":\"1\",\"②\":\"2\",\"③\":\"3\",\"④\":\"4\",\"⑤\":\"5\",\"⑥\":\"6\",\"⑦\":\"7\",\"⑧\":\"8\",\"⑨\":\"9\",\n",
        "             \"⑩\":\"10\",\"⑪\":\"11\",\"⑫\":\"12\",\"⑬\":\"13\",\"⑭\":\"14\",\"⑮\":\"15\",\n",
        "             \"⑯\":\"16\",\"⑰\":\"17\",\"⑱\":\"18\",\"⑲\":\"19\",\"⑳\":\"20\",',':'',\"&\":\"\",\"-\":\"\",\n",
        "             \"PASS\":\"PASS\",\"RUN\":\"RUN\",\"FG\":\"FG\",\"PUNT\":\"PUNT\",\"し\":\"L\",\"、\":\" \"}\n",
        "\n",
        "!rm -r /content/ocr/\n",
        "!mkdir /content/ocr/\n",
        "\n",
        "def ocr2txt(fname):\n",
        "    txt = tool.image_to_string(\n",
        "        Image.open(fname),\n",
        "        lang=\"jpn\",\n",
        "        builder=pyocr.builders.TextBuilder(tesseract_layout=6)\n",
        "        )\n",
        "    # プレーに関係ありそうな文字として　\"&\",'Penalty','Kick-off','Extra Point','TIMEOUT','Quarter'が含まれる行だけ抽出する\n",
        "    # そのほかの特定文字も抽出対象としたい場合は ifの次に or ('' & in line) を追加挿入し、''の間に含めたい文字列を指定するとできますよ\n",
        "    return  [line for line in txt.splitlines() if ('&' in line) or ('Penalty' in line) or ('Kick-off' in line) or ('Extra Point' in line) or ('TIMEOUT' in line) or (':' in line) or ('Quarter' in line)]\n",
        "    \n",
        "def num_conv(line):\n",
        "    for ct in conv_text:\n",
        "        line = line.replace(ct,conv_text[ct])\n",
        "    return line\n",
        "\n",
        "#フォルダに出力された画像ファイルの一覧を取得\n",
        "jpg_list = glob.glob('/content/image/*.jpg')\n",
        "\n",
        "#画像ファイルをからOCRでデータ化したものを一つのファイルにまとめる\n",
        "output_file = []\n",
        "for row in sorted(jpg_list):\n",
        "    output_file.append([row1.replace(' ','') for row1 in [num_conv(out_txt) for out_txt in ocr2txt(row)]])\n",
        "\n",
        "output_txt = ''\n",
        "for x in output_file:\n",
        "    for z in x:\n",
        "        output_txt += z+'\\n'\n",
        "\n",
        "\n",
        "#最後にテキストファイルを出力する\n",
        "output_file_txt = '/content/ocr/'+jpg_list[0][15:23]\n",
        "with open(output_file_txt,mode='w') as f:\n",
        "    f.write(output_txt)\n",
        "\n",
        "print('9 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0h0PzJ1M9N9"
      },
      "source": [
        "import re\n",
        "import glob\n",
        "import pandas as pd \n",
        "\n",
        "# team_name ={'富士通フロ':'FF','IBMBi':'BB'}\n",
        "team_name ={'富士通フロ':'FF','パナソニッ':'PI'}\n",
        "\n",
        "\n",
        "tname = [row for row in team_name.values()]\n",
        "\n",
        "filename = glob.glob('/content/ocr/*')[0]\n",
        "\n",
        "with open(filename,mode='r',encoding='UTF-8') as f:\n",
        "    file_in = f.readlines()\n",
        "\n",
        "in_list = [row for row in file_in]\n",
        "\n",
        "def find(s,q,t):\n",
        "    # fp = re.search(r'\\w\\w\\d+[LMR]', s)\n",
        "    # if fp is not None:\n",
        "    team = t\n",
        "    qt = q\n",
        "    fp_all = fp.group()\n",
        "    fieldpos = fp_all[:2]\n",
        "    y = re.search(r'\\d+',fp_all[2:])\n",
        "    yardline = y.group()\n",
        "    hash = fp_all[-1]\n",
        "    down = s[:1] \n",
        "    tg = re.search(r'\\d\\d',s[2:])\n",
        "    if tg is not None:\n",
        "        togo = tg.group()\n",
        "    else:\n",
        "        togo = 0\n",
        "    yd = re.search(r'-*\\d+y',s)\n",
        "    if yd is not None:\n",
        "        if 'ロス' in s:\n",
        "            yards = 0 - int(yd.group()[:-1])\n",
        "        else:\n",
        "            yards = yd.group()[:-1]\n",
        "    else:\n",
        "        yards = 0\n",
        "    if 'RUN' in s:\n",
        "        play = 'RUN'\n",
        "    elif 'PASS' in s:\n",
        "        play = 'PASS'\n",
        "    elif 'PUNT' in s:\n",
        "        play = 'PUNT'\n",
        "    else:\n",
        "        play = 'None'\n",
        "    if team != fieldpos:\n",
        "        yardline = 100- int(yardline)\n",
        "    other = s.replace(',','')\n",
        "    other = other.replace('\\n','')\n",
        "    return qt,team,int(down),int(togo),fieldpos,int(yardline),hash,play,int(yards),other\n",
        "\n",
        "def set_q(s):\n",
        "    # quarter = re.search(r'Quarter', s)\n",
        "    # if quarter:\n",
        "    fq,sq,tq,yd = '','','',''\n",
        "    fq = re.search(r'First', s)\n",
        "    sq = re.search(r'Second', s)        \n",
        "    tq = re.search(r'Third', s)        \n",
        "    yq = re.search(r'Fourth', s)\n",
        "    if fq:\n",
        "        q = 1\n",
        "    elif sq:\n",
        "        q = 2\n",
        "    elif tq:\n",
        "        q = 3\n",
        "    elif yq:\n",
        "        q = 4\n",
        "    return q\n",
        "\n",
        "def team(s):\n",
        "    for row in team_name:\n",
        "        if row in s[:5]:\n",
        "            return team_name[row]\n",
        "\n",
        "lines_strip_kekka = []\n",
        "for s in in_list:\n",
        "    quarter = re.search(r'Quarter', s)\n",
        "    if quarter:\n",
        "        q = set_q(s)\n",
        "    tm = team(s)\n",
        "    if tm is not None:\n",
        "        t = tm\n",
        "    fp = re.search(r'\\w\\w\\d+[LMR]', s)\n",
        "    if fp:\n",
        "        f = find(s,q,t)\n",
        "    else:\n",
        "        f = s[:-1],0,0,0,0,0,0,0\n",
        "    if f is not None:\n",
        "        lines_strip_kekka.append(f)\n",
        "\n",
        "kekka = pd.DataFrame(lines_strip_kekka,columns=['quarter','offence','down','togo','fieldposition','yardline','hash','play','yards','other'])\n",
        "kekka[(kekka['offence']==tname[0])|(kekka['offence']==tname[1])].to_csv(filename[14:]+'.csv',index=False)"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-9JDeocLhkq"
      },
      "source": [
        "### おまけのおまけ\n",
        "この処理を上から番号順に実行させればGoogle Colabo環境(中身はJupyter notebook)でPDFデータから文字を抜き出す処理まではできるようになっています。\n",
        "\n",
        "で、データ分析のためのデータ整備の本番はこれからになりますが、この時点ですでに印刷された文字をデータ化できているので、ファイルをダウンロードした後に、自分で項目を分割してやればエクセルなどパソコン上でデータとして扱えるようになります。\n",
        "\n",
        "### 注意）ダウンロードしたファイルはまだ整備されていないので、このままで素直にエクセル等で開くことは出来ないかも知れません。まずはメモ帳などで修正してからエクセル等で開いて下さい。\n",
        "\n",
        "処理を自動化することは作業の効率化という点で非常に大切ですが、意味が分からずやるよりも最初はデータ構造を（なんとなくでも）理解しながら作業を行った方が、後々データの見直しや分析のやり方を見直したいときのアイディアがひらめく可能性が高くなると思います。\n",
        "\n",
        "今回ダウンロードできるファイル(stats.txt)はパソコンのメモ帳で開けば、普通の文字列として読んだり修正したりすることができます。分割したい項目をカンマ(,)で区切ってあげて保存した後にファイル名の拡張子をCSVにすれば、それはもう立派なCSVデータです。（CSVは　Comma-Separated Valuesの略で、文字通りカンマで項目が区切られているデータというだけの意味です。拡張子自体はパソコン自体が処理を楽にするためにつけられている文字列というだけなので、自分が処理させたいプログラムに紐づけられたものに勝手に変えてもオーケーです）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UYl4q-WSNrN"
      },
      "source": [
        "## とりあえず今回の最後に\n",
        "現在、機械学習などが活用されその精度は上がってきてはいるものの、OCR処理で読み取り間違い発生をゼロにすることはなかなか難しい状況です。特に今回のような数字と記号、漢字とアルファベットが混ざったものをプログラム処理だけですべてきれいなデータが作成できないと考えた方が良いと思います。（元データ自体、半角と全角の数字が混ざっているかもしれないし）\n",
        "\n",
        "そのため、結局最後は人間が目で確認しながら手で微調整をする必要があります。今回はそれほど大きいデータ量ではないので、心の中では初めから手入力でCSVファイルを作成したほうが良いかもともしれないなと思います。しかし、一からデータ登録をすることを考えるとやる気がなくなってしまうので、こういった下準備が気軽にできる環境が生み出されてきていることには大きな意義があることは確かです。\n",
        "\n",
        "だだそれ以前に、データ提供されている側にはPDFデータを作るためにエクセルなどで準備しているんじゃないかと思われ、ならばそのデータを（PDFの参考データとしてでも）公開してくれれば、少なくともOCR処理での読み取り間違いなどの発生はなくなり、よりデータを活用しやすくなります。\n",
        "\n",
        "しかしながら、現在のデータではPASSやPUNTなどの投げたりけったりした選手と、それを受けたりリターンしたりした選手の区別などデータの整理整頓（標準化）ができておらず、突っ込んだ分析や機械学習にこのデータを使おうとした場合にはまだまだ問題は山積状態です。\n",
        "\n",
        "そんな五里霧中な状態ではあるものの、我々にはNFLという偉大な先達がおられます。彼らがこれまで積み上げてきたノウハウの端っこでも参考にしながら、もっとデータ活用できる環境が構築されることの切望します。\n",
        "\n",
        "※もしトップレベルのチームではそういったデータ取得、活用ノウハウが共通化されているならば、それについて教えてください。\n",
        "\n",
        "一度に理想まで近づくことはできませんが、まずは手始めに野球のスコアブックのようなデータ採取の標準フォーマットを決めて、それが各チームで広く使われるようにすることが必須でしょう。そうすれば、それを基にしたツール開発や、データ自体の流通や活用が円滑に行わえるようになると考えます。\n",
        "\n",
        "これからもっと「データドリブン（データをもとに物事を進めてゆく）」な世の中になると思います。身近なことからコツコツと、できることからやってみましょう。"
      ]
    }
  ]
}