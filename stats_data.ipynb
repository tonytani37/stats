{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "スタッツデータ作成.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPx3txhzDyQWvSttisJG2qm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonytani37/stats/blob/main/stats_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U4jZqO9cwDw"
      },
      "source": [
        "# 前提条件\n",
        "Googleアカウントが必須です。\n",
        "\n",
        "ブラウザは最新のChromeの利用を強く推奨します。(Microsoft Edgeの最新版は大丈夫ですが、古いEdgeやIEは動かないかもしれません。FirefoxやSafariでは動くと思いわれます）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9YB5vUGa9Hr"
      },
      "source": [
        "## 注意事項\n",
        "### パソコンが古くても、処理自体は膨大な能力を持つGoogleクラウド上で実行されるので、目の前のPCが多少古くてもあまり心配することはありません。\n",
        "\n",
        "１．説明を読んで、上から順番に番号順に処理をしてください。\n",
        "\n",
        "２．処理はそれぞれの機能ごとに分けてありますので、今後修正したい場合にはその部分だけ差し替えればオーケーです。\n",
        "\n",
        "３．処理によっては実行するとその下によくわからない文字がずらずらと表示されるものとされないものがあります。どのタイミングで処理が終わったかわかりづらいかもしれないので、各処理が完了すると「x おわり」と表示するようにしていますで、そこまで我慢してください。（表示されるメッセージのnは処理の番号です）\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObTBQNY4PHhR"
      },
      "source": [
        "### データ化したいPDFファイルを入手します\n",
        "1-1 は自分のPCにあるPDFファイルを変換したい場合に使います。\n",
        "\n",
        "1-2 はよくわからないけどとりあえず練習用に試してみたい人向けに、Xリーグのホームページにある2019/8/24の富士通フロンティアーズ対IBM BigBlueの対戦のものがダウンロードされます。\n",
        "\n",
        "どちらか一つ、好きな方を実行してください。（1-1の場合は、以降使われるPDFファイル名や画像データ名が以下にあるものと異なるので、適宜変更してくださいね）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVn2bJvtQNcT"
      },
      "source": [
        "その１）自分のPCにあるPDFファイルを変換したい場合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leVVAUOrc46Y"
      },
      "source": [
        "# 1-1\n",
        "#OCRであつかうPDFファイルを読み込む（変換したいPC上のファイルを指定してくだされ）\n",
        "from google.colab import files\n",
        "f = files.upload()\n",
        "#読み込んだ画像のファイル名\n",
        "filename = list(f)[0]\n",
        "\n",
        "print('1-1 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaZIBzcHQSZE"
      },
      "source": [
        "その２）とりあえず試してみたい場合　"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1pjztOfP8N9"
      },
      "source": [
        "# 1-2\n",
        "#OCRであつかうPDFファイルを読み込む（練習用に特定のPDFファイルをダウンロードしてくる）\n",
        "! wget -c -P '/content/' 'https://xleague.s3.ap-northeast-1.amazonaws.com/wp-content/uploads/2019/07/20190824_X1_FF_BB_921.pdf'\n",
        "filename = \"20190824_X1_FF_BB_921.pdf\"\n",
        "print('1-2 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVU-xfCkNtVg"
      },
      "source": [
        "### PDFから画像へ変換します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5NhxslFWovy"
      },
      "source": [
        "# 2\n",
        "# PDFから画像へ変換するためのライブラリ、ツールを準備する\n",
        "!apt-get install poppler-utils \n",
        "!pip install pdf2image\n",
        "print('2 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX0BTtORaolH"
      },
      "source": [
        "# 3\n",
        "# 画像データに変換する処理\n",
        "from pathlib import Path\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "# Google Colabのデフォルト環境内にimageというフォルダを作る\n",
        "!rm -r /content/image/\n",
        "!mkdir /content/image/\n",
        "\n",
        "pdf_path = Path(filename)\n",
        "#outputのファイルパス（この場合は上でつくったimageフォルダを指定）\n",
        "img_path=Path(\"/content/image/\")\n",
        "\n",
        "#変換されたjpegファイルが保存されます\n",
        "convert_from_path(pdf_path, output_folder=img_path,fmt='jpeg',output_file=pdf_path.stem)\n",
        "print('3 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElrGaxyMN7HG"
      },
      "source": [
        "### 以上で画像変換完了。PDFに複数ページがある場合、ページごとに画像データ（ファイル名末尾が連番）が作成されるので、一つのPDFファイルから複数の画像ファイルが作成されたとしても、驚かないこと。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fXjEWqCNm-c"
      },
      "source": [
        "### ここからOCR読み込みについて。まずは準備しましょう\n",
        "まずはOCR読み込み用のライブラリとツールをインストールします"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAGP267sZB4D"
      },
      "source": [
        "# 4\n",
        "# Tesseract OCRの関連ライブラリを準備する\n",
        "# OCR読み込みに必要なツールをインストールします\n",
        "!apt install tesseract-ocr\n",
        "!apt install libtesseract-dev\n",
        "!pip install pyocr\n",
        "print('4 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHwdTN3PZLoc"
      },
      "source": [
        " # 5\n",
        " #日本語トレーニングデータのダウンロードとして環境設定します\n",
        "!curl -L https://github.com/tesseract-ocr/tessdata/raw/master/jpn.traineddata > jpn.traineddata\n",
        "!cp jpn.traineddata /usr/share/tesseract-ocr/4.00/tessdata\n",
        "print('5 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXoCx9rLZR4n"
      },
      "source": [
        "# 6\n",
        "# PythonでOCR読み込み変換に必要なライブラリを準備します\n",
        "import pyocr\n",
        "import pyocr.builders\n",
        "print('6 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbZOm_6eOWLX"
      },
      "source": [
        "### OCR読み込みの前に、必要なツールがインストールされているか確認しませう。\n",
        "うまくいかない場合は環境構築が間違っているので、最初からもう一度がんばろう。「ワシはPython先生だから」と自信満々な人は、7,8を飛ばしてもオーケー。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcjK7gd2XROO"
      },
      "source": [
        "OCR tool is 'Tesseract (sh)' と表示されればオーケー"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJIfOdP4ZXTV"
      },
      "source": [
        "# 7\n",
        "#OCRが使用可能かの設定状態チェックしてみる\n",
        "tools = pyocr.get_available_tools()\n",
        "if len(tools) == 0:\n",
        "    print(\"OCR tool is not found\")\n",
        "    sys.exit(1)\n",
        "\n",
        "#OCRツール名を表示\n",
        "tool = tools[0]\n",
        "print(\"OCR tool is '%s'\" % (tool.get_name()))\n",
        "print('7 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC_wIocpXWYn"
      },
      "source": [
        "Available languages:　の次に　jpn　が入ってればオーケー（その他 osd,engなどもあるはず。もしかするとないものもあるかもしれないけど、とりあえず jpn が入っていればオーケー）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47wmY8pRZeMV"
      },
      "source": [
        "# 8\n",
        "#OCR対応言語を表示して'jpn'が入っているか確認してみる\n",
        "langs = tool.get_available_languages()\n",
        "print(\"Available languages: %s\" % \", \".join(langs))\n",
        "lang = langs[0]\n",
        "print(\"Will use lang '%s'\" % (lang))\n",
        "print('8 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdYp8pLyOjmY"
      },
      "source": [
        "### ここから実際のOCR読み込み処理です。\n",
        "ここでは、fnameという変数にファイルのパスをセットしています。Google Colaboでは画面左側に作成されたファイルを扱うので、デフォルトの'/content/以降の部分に読み込みたい画像ファイル名(pathも正しく指定してね)を指定してください。ファイル名とパスの指定は、読み込みたいファイルを右クリックすると「パスをコピー」という項目があるので、そいつをクリックしてコピーし、fname = 以降に”または’のどちらかで囲って、その間にペーストすればオーケーです。\n",
        "\n",
        "(本当は特定のフィルだにある画像ファイルを一括で処理できればいいんだろうけれど、そういうやつは次に考えます）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haMQ6aWDeOxw"
      },
      "source": [
        "# 9\n",
        "#読み込んだ画像をOCRでテキスト抽出。\n",
        "\n",
        "#読み込む画像ファイルを指定する（自分でPDFを指定した場合は、このファイル名を変更すること）\n",
        "fname = '/content/image/20190824_X1_FF_BB_9210001-06.jpg'\n",
        "\n",
        "txt = tool.image_to_string(\n",
        "    Image.open(fname),\n",
        "    lang=\"jpn\",\n",
        "    builder=pyocr.builders.TextBuilder(tesseract_layout=6)\n",
        "    )\n",
        "\n",
        "# プレーに関係ありそうな文字として　\"&\",'Penalty','Kick-off','Extra Point','TIMEOUT','Quarter'が含まれる行だけ抽出する\n",
        "# そのほかの特定文字も抽出対象としたい場合は ifの次に or ('' & in line) を追加挿入し、''の間に含めたい文字列を指定するとできますよ\n",
        "lines_strip = [line for line in txt.splitlines() if ('&' in line) or ('Penalty' in line) or ('Kick-off' in line) or ('Extra Point' in line) or ('TIMEOUT' in line) or (':' in line) or ('Quarter' in line)]\n",
        "print('9 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwvIjI36SVmz"
      },
      "source": [
        "### 私の環境ではなんだか数字の読み取り変換がうまくいってない様子なので、マル付き数字をむりやり半角数字（str型）に置き換える。同時に文字間の不規則な空白をすべて左詰めにする\n",
        "うまくいっている場合にこれを動かしても（あえてマル付き数字を使っている場合以外は）なんの影響もないはずです。\n",
        "\n",
        "またここでは文字化したときに不規則に挿入されてしまっている文字間の空白を埋める処理もしていますので、以降の正規化文字判定などで役に立つと思います。\n",
        "\n",
        "なので、とりあえず動かしてみてください。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yz_rfcRBcZb"
      },
      "source": [
        "# 10\n",
        "# 置き換わらないマル数字（やその他の文字）が出てきたら、conv_text辞書に追加してね。形式は辞書のkey:valueです）\n",
        "\n",
        "# 置き換えたい文字をkey:value形式で定義している辞書形式のデータです\n",
        "conv_text = {\"①\":\"1\",\"②\":\"2\",\"③\":\"3\",\"④\":\"4\",\"⑤\":\"5\",\"⑥\":\"6\",\"⑦\":\"7\",\"⑧\":\"8\",\"⑨\":\"9\",\n",
        "             \"⑩\":\"10\",\"⑪\":\"11\",\"⑫\":\"12\",\"⑬\":\"13\",\"⑭\":\"14\",\"⑮\":\"15\",\n",
        "             \"⑯\":\"16\",\"⑰\":\"17\",\"⑱\":\"18\",\"⑲\":\"19\",\"⑳\":\"20\"}\n",
        "\n",
        "# 文字置き換え用の関数：渡された引数（文字列）に対してkeyと同じ文字がconv_textあったらvalueに置き換える処理を、conv_textの頭から順番にやっとります\n",
        "def num_conv(line):\n",
        "    for ct in conv_text:\n",
        "        line = line.replace(ct,conv_text[ct])\n",
        "    return line\n",
        "\n",
        "# 変換された元のデータを一行づつ関数を呼び文字を置き換えた後、スペースを削って左へシフトさせてリスト形式のデータにしています\n",
        "lines_strip_after =  [''.join(a.split(' ')) for a in [num_conv(line) for line in lines_strip]]\n",
        "\n",
        "# 変換した結果を試し打ち（アタマの大会名とケツ２行の対戦チームの成績は表示しとりません\n",
        "for a in lines_strip_after[1:-2]:\n",
        "    print(a)\n",
        "\n",
        "print('10 おわり')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y8sS37YEnrw"
      },
      "source": [
        "### うまく文字化されていましたか？\n",
        "ここまでの処理で　\n",
        "\n",
        "PDFファイルの準備→ページごとに画像データ化→画像データから文字抽出→プレーに関係ありそうな行だけ抜きだし　\n",
        "\n",
        "が完了しました。PDFファイルや画像データと比較してみて、どれくらいうまく処理されたか確認しましょう。変な文字に変換されるときは、まずはPDFファイルや画像データ自体の精度が低いことが考えられますので、それらの対応は各自ググってみてください。（日本語変換用のトレーニングデータをブラッシュアップするという手もありますので、できる人はチャレンジして成功したら結果を広く公開してください）\n",
        "\n",
        "以降、抜き出した文字データをそれぞれ意味がある項目に分割しなければなりません。これは「正規表現」をつかって意味がある文字を抜き出す処理となります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNmAta3FRrcf"
      },
      "source": [
        "### おまけ\n",
        "PDFからデータ化した結果を、自分のPCにダウンロードできますよ。\n",
        "\n",
        "注意）Google Colaboは一定時間ほったらかしておくと、せっかく作ったデータが消えてしまいます。（処理プログラム自体は自動的にセーブされているので安心）　データを残したい場合は必要なデータをダウンロードするか、保存場所をGoogle ColaboからGoogle Driveへ変更してください。(Google Driveをマウントする方法などは、各自ググってください。親切な人たちが書いたたくさんの事例が見つかります）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdRJtSFCcLkw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "2b1d30fa-86c3-4c75-b5ed-940d870d59b3"
      },
      "source": [
        "# OCR処理をした結果文を出力したいときに使う（左側にstats.txtという名前のファイルができる）\n",
        "\n",
        "# 同じファイル名で繰り返し処理をすると上書きされるので、複数ファイルを扱うとkにはtxt_nameにファイル名を指定してね\n",
        "txt_name = \"stats01.txt\"\n",
        "\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "# いろいろいじくってリストにしたのでpandasを使って出力する\n",
        "df = pd.DataFrame(lines_strip_after)\n",
        "df.to_csv(txt_name,header=False,index=False)\n",
        "\n",
        "\n",
        "# 続いて作成されたファイルをダウンロードしようとします\n",
        "# ダウンロードしたくない場合には以下の行をコメントにするか、保存画面が出てきたらキャンセルするとかしてね\n",
        "files.download(txt_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d9288cae-8a88-4222-a140-33dec542ea3d\", \"stats01.txt\", 2984)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-9JDeocLhkq"
      },
      "source": [
        "### おまけのおまけ\n",
        "この処理を上から番号順に実行させればGoogle Colabo環境(中身はJupyter notebook)でPDFデータから文字を抜き出す処理まではできるようになっています。\n",
        "\n",
        "で、データ分析のためのデータ整備の本番はこれからになりますが、この時点ですでに印刷された文字をデータ化できているので、ファイルをダウンロードした後に、自分で項目を分割してやればエクセルなどパソコン上でデータとして扱えるようになります。\n",
        "\n",
        "処理を自動化することは作業の効率化という点で非常に大切ですが、意味が分からずやるよりも最初はデータ構造を（なんとなくでも）理解しながら作業を行った方が、後々データの見直しや分析のやり方を見直したいときのアイディアがひらめく可能性が高くなると思います。\n",
        "\n",
        "今回ダウンロードできるファイル(stats01.txt)はパソコンのメモ帳で開けば、普通の文字列として読んだり修正したりすることができます。分割したい項目をカンマ(,)で区切ってあげて保存した後にファイル名の拡張子をCSVにすれば、それはもう立派なCSVデータです。（CSVは　Comma-Separated　Valuesの略で、文字通りカンマで項目が区切られているデータというだけの意味です。拡張子自体はパソコン自体が処理を楽にするためにつけられている文字列というだけなので、自分が処理させたいプログラムに紐づけられたものに勝手に変えてもオーケーです）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UYl4q-WSNrN"
      },
      "source": [
        "## とりあえず今回の最後に\n",
        "現在、機械学習などが活用されその精度は上がってきてはいるものの、OCR処理で読み取り間違い発生をゼロにすることはなかなか難しい状況です。特に今回のような数字と記号、漢字とアルファベットが混ざったものをプログラム処理だけですべてきれいなデータが作成できないと考えた方が良いと思います。（元データ自体、半角と全角の数字が混ざっているかもしれないし）\n",
        "\n",
        "そのため、結局最後は人間が目で確認しながら手で微調整をする必要があります。正直な気持ちとしては今回はそれほど大きいデータ量ではないので、初めから手入力でCSVファイルを作成したほうが良いかもとも思います。しかし、一からデータ登録をすることを考えるとやる気がなくなってしまうので、こういった下準備が気軽にできる環境が生み出されてきていることには大きな意義があると思います。\n",
        "\n",
        "だだそれ以前に、データ提供されている側にはPDFデータを作るためにエクセルなどで準備しているんじゃないかと思われ、ならばそのデータを（PDFの参考データとしてでも）公開してくれれば、少なくともOCR処理での読み取り間違いなどの発生はなくなり、よりデータを活用しやすくなります。\n",
        "\n",
        "しかしながら、現在のデータではPASSやPUNTなどの投げたりけったりした選手と、それを受けたりリターンしたりした選手の区別などデータの整理整頓（標準化）ができておらず、突っ込んだ分析や機械学習にこのデータを使おうとした場合にはまだまだ問題は山積状態です。\n",
        "\n",
        "そんな五里霧中な状態ではあるものの、我々にはNFLという偉大な先達がおられます。彼らがこれまで積み上げてきたノウハウの端っこでも参考にしながら、もっとデータ活用できる環境が構築されることの切望します。\n",
        "\n",
        "※もしトップレベルのチームではそういったデータ取得、活用ノウハウが共通化されているならば、それについて教えてください。\n",
        "\n",
        "一度に理想まで近づくことはできませんが、まずは手始めに野球のスコアブックのようなデータ採取の標準フォーマットを決めて、それが各チームで広く使われるようにすることが必須でしょう。そうすれば、それを基にしたツール開発や、データ自体の流通や活用が円滑に行わえるようになると考えます。\n",
        "\n",
        "これからもっと「データドリブン（データをもとに物事を進めてゆく）」な世の中になると思います。身近なことからコツコツと、できることからやってみましょう。"
      ]
    }
  ]
}